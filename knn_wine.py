# -*- coding: utf-8 -*-
"""KNN-WINE

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YICgpRs8JwV_zNAD6CzDWrDsZcy8sLLP

# FREE WINE DATASET FROM
# Aeberhard, S. & Forina, M. (1992). Wine [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5PC7J.
"""

import pandas as pd
import numpy as np

from sklearn.datasets import load_wine
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# carregar dataset
wine = load_wine()

# criar estrutura dataframe
df = pd.DataFrame(wine.data, columns=wine.feature_names)

# adicionar targets no df, 0=Barolo , 1=Chianti , 2=Montepulciano
df['target'] = wine.target
df['target'] = df['target'].replace({0: 'Barolo', 1: 'Chianti', 2: 'Montepulciano'})

df.head(5)

df.describe()

x = wine.data
y = wine.target

print(x.shape, y.shape)

"""# KNN com Holdout simples (70% treino - 30% teste)"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=47, stratify=y)

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)

# Definir o modelo KNN com k=3
classifier1 = KNeighborsClassifier(n_neighbors=3)

# Treinar o modelo com os dados de treinamento
classifier1.fit(x_train, y_train)

# avaliar
acc_holdout = classifier1.score(x_test, y_test)
print(f'Accuracy Holdout: {acc_holdout*100}%')

"""# KNN com Holdout Repetido (70% treino - 30% teste)"""

from sklearn.model_selection import ShuffleSplit, cross_val_score

classifier_repetido = KNeighborsClassifier(n_neighbors=3)

cv_shuffle = ShuffleSplit(n_splits = 100, test_size = 0.3, random_state = 42)

acc_repetido = cross_val_score(classifier_repetido, x, y, cv=cv_shuffle)

print(acc_repetido)
print('------------------------------------------------------------')
print(f'Media Accuracy Holdout Repetido: {acc_repetido.mean()*100:.3f}%')

"""# KNN com Validacao Cruzada | K-FOLD"""

acc_kfold = cross_val_score(classifier_repetido, x, y, cv=40)

print(acc_kfold)
print('------------------------------------------------------------')
print(f'Media Accuracy K-Fold: {acc_kfold.mean()*100:.3f}%')



from sklearn.model_selection import cross_val_score

def tune_knn_n_neighbors(x, y, n_neighbors_range):
    """
    Tunes the n_neighbors hyperparameter for a KNN classifier using cross-validation.

    Args:
        x: The feature data.
        y: The target labels.
        n_neighbors_range: A list or range of n_neighbors values to test.

    Returns:
        The best n_neighbors value found.
    """
    best_score = 0
    best_n_neighbors = 0

    for n in n_neighbors_range:
        knn = KNeighborsClassifier(n_neighbors=n)
        scores = cross_val_score(knn, x, y, cv=5)  # Using 5-fold cross-validation
        mean_score = scores.mean()

        if mean_score > best_score:
            best_score = mean_score
            best_n_neighbors = n

    print(f"Best n_neighbors: {best_n_neighbors}")
    print(f"Best cross-validation accuracy: {best_score:.3f}")
    return best_n_neighbors

# Example usage:
n_neighbors_to_test = range(1, 21)  # Test n_neighbors from 1 to 20
best_k = tune_knn_n_neighbors(x, y, n_neighbors_to_test)